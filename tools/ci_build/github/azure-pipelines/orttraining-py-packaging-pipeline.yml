trigger: none

stages:
# - template: templates/py-packaging-stage.yml
#   parameters:
#     enable_training: true
#     enable_linux_cpu: false
#     enable_linux_gpu: true
#     enable_windows_cpu: false
#     enable_windows_gpu: false
#     enable_mac_cpu: false
#     python_version_strategy_matrix:
#       Python36:
#         python.version: '3.6'

- stage: Test_Wheel
  condition: succeededOrFailed()
  jobs:
  - job: Test_Wheel_Ubuntu_GPU
    pool: Linux-GPU-CUDA10
    strategy:
      matrix:
        Python36:
          python.version: '3.6'

    steps:
    - checkout: self
      clean: true
      submodules: false

    - template: templates/set-py-packaging-variables-step.yml

    # - task: DownloadPipelineArtifact@2
    #   inputs:
    #     source: current
    #     artifact: onnxruntime_gpu
    #     patterns: '**/*-$(python.whl.impl.abi.tags)-manylinux2014_x86_64.whl'
    #     path: $(Pipeline.Workspace)/artifacts
    #   displayName: 'Download wheel'

    - task: DownloadPipelineArtifact@2
      inputs:
        buildType: 'specific'
        project: '2a773b67-e88b-4c7f-9fc0-87d31fea8ef2'
        definition: '99'
        buildVersionToDownload: 'latestFromBranch'
        branchName: 'refs/heads/edgchen1/training_wheel'
        allowPartiallySucceededBuilds: true
        allowFailedBuilds: true
        artifactName: 'onnxruntime_gpu'
        itemPattern: '**/*-$(python.whl.impl.abi.tags)-manylinux2014_x86_64.whl'
        targetPath: '$(Pipeline.Workspace)/artifacts'
      displayName: 'Download wheel'

    - script: |
        docker build \
          --pull \
          -t onnxruntime-training-ubuntu-gpu-test \
          --build-arg BUILD_USER=onnxruntimedev \
          --build-arg BUILD_UID=$(id -u) \
          -f Dockerfile.ubuntu_gpu .
      displayName: 'Build docker image'
      workingDirectory: $(Build.SourcesDirectory)/tools/ci_build/github/linux/docker
    - script: |
        HOST_WHEEL_PATH=$( \
          find "$(Pipeline.Workspace)/artifacts" -name "*-$(python.whl.impl.abi.tags)-manylinux2014_x86_64.whl" \
          | tail -n 1 ) && \
        ls "${HOST_WHEEL_PATH}" && \
        docker run \
          --rm \
          --gpus all \
          --volume $(Build.SourcesDirectory):/onnxruntime_src \
          --volume $(Pipeline.Workspace)/artifacts:/artifacts \
          onnxruntime-training-ubuntu-gpu-test /bin/bash -c " \
            PYTHON_VERSION=$(python.version) \
            CONDA_INSTALL_DIR=/opt/miniconda3 \
            /onnxruntime_src/tools/ci_build/run_in_temp_conda_env.sh \
              /onnxruntime_src/tools/ci_build/run_python_tests_with_wheel.py \
                --wheel-path ${HOST_WHEEL_PATH/#"$(Pipeline.Workspace)/artifacts"/"/artifacts"} \
            "
      displayName: 'Run Python tests with wheel'
    - template: templates/clean-agent-build-directory-step.yml